{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c21a832",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292395b",
   "metadata": {},
   "source": [
    "use Markdown cells to describe what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3da867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4\n",
    "import pandas as pd\n",
    "import re\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237859c",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d333efa",
   "metadata": {},
   "source": [
    "## Uber Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber=pd.read_csv(\"uber_rides_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(row):\n",
    "    R = 6373.0\n",
    "    \n",
    "    lon1 = radians(row[\"pickup_longitude\"])\n",
    "    lat1 = radians(row[\"pickup_latitude\"])\n",
    "    \n",
    "    lon2 = radians(row[\"dropoff_longitude\"])\n",
    "    lat2 = radians(row[\"dropoff_latitude\"])\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67515cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uber_data_cleaning(df_uber):\n",
    "    df_uber.dropna()\n",
    "    df_uber.drop(\"Unnamed: 0\" , axis=1, inplace=True)\n",
    "    \n",
    "    pick_long_check=(df_uber[\"pickup_longitude\"]>= -74.242330) & (df_uber[\"pickup_longitude\"]<= -73.717047)\n",
    "    drop_long_check=(df_uber[\"dropoff_longitude\"]>= -74.242330) & (df_uber[\"dropoff_longitude\"]<= -73.717047)\n",
    "    pick_latt_check=(df_uber[\"pickup_latitude\"]>= 40.560445) & (df_uber[\"pickup_latitude\"]<= 40.908524)\n",
    "    drop_latt_check=(df_uber[\"dropoff_latitude\"]>= 40.560445) & (df_uber[\"dropoff_latitude\"]<= 40.908524)\n",
    "\n",
    "    df_uber=df_uber[pick_long_check & drop_long_check & pick_latt_check & drop_latt_check]\n",
    "    \n",
    "    df_uber['pickup_datetime'] = pd.to_datetime(df_uber['pickup_datetime'])\n",
    "    df_uber['pickup_datetime']=df_uber['pickup_datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df_uber['distance'] = df_uber.apply(distance, axis=1)\n",
    "    \n",
    "    return df_uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber=uber_data_cleaning(df_uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d0e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028708e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ca56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_uber.to_csv('uber_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf074d9",
   "metadata": {},
   "source": [
    "## Yellow Taxi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_parser(): \n",
    "    # Scrapping out link for each of yellow trip data\n",
    "    \n",
    "    response = requests.get('https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page')\n",
    "    soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "    parse = str(soup.find_all(\"li\")).split()\n",
    "    pattern = re.compile(r\"href=\\\"https:\\/\\/s3\\.amazonaws\\.com\\/nyc\\-tlc\\/trip\\+data\\/yellow\\_tripdata\\_20[0-1]\\d\")\n",
    "    newlist = list(filter(pattern.match, parse))\n",
    "    newlist = newlist[42:]\n",
    "    linklist=[]\n",
    "    for item in newlist:\n",
    "        linklist.append(item.split('href=\"')[1][:-1])\n",
    "    return linklist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linklist=link_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_taxi_dataset(linklist):\n",
    "    result=pd.DataFrame()\n",
    "    #Data collection of 2015's yellow taxi data\n",
    "    for link in linklist[:12]:\n",
    "        req = requests.get(link)\n",
    "        url_content = req.content\n",
    "    \n",
    "        s=str(url_content,'utf-8')\n",
    "        data = StringIO(s) \n",
    "        df=pd.read_csv(data, error_bad_lines=False)\n",
    "        df.drop(\"improvement_surcharge\" , axis=1, inplace=True)\n",
    "        df = df.iloc[: , :-1]\n",
    "        df.columns=['vendor_id','pickup_datetime','dropoff_datetime','passenger_count','trip_distance','pickup_longitude',\n",
    "                'pickup_latitude','rate_code','store_and_fwd_flag','dropoff_longitude','dropoff_latitude','payment_type',\n",
    "                'fare_amount','surcharge','mta_tax','tip_amount','tolls_amount','total_amount']\n",
    "        df = df.sample(n=3000)\n",
    "    \n",
    "        result=result.append(df)\n",
    "    #Data collection of years from 2009 to 2014    \n",
    "    for link in linklist[12:]:\n",
    "        req = requests.get(link)\n",
    "        url_content = req.content\n",
    "    \n",
    "        s=str(url_content,'utf-8')\n",
    "        data = StringIO(s) \n",
    "        df=pd.read_csv(data, error_bad_lines=False)\n",
    "        df.columns=['vendor_id','pickup_datetime','dropoff_datetime','passenger_count','trip_distance','pickup_longitude',\n",
    "                'pickup_latitude','rate_code','store_and_fwd_flag','dropoff_longitude','dropoff_latitude','payment_type',\n",
    "                'fare_amount','surcharge','mta_tax','tip_amount','tolls_amount','total_amount']\n",
    "        df = df.sample(n=3000)\n",
    "    \n",
    "        result=result.append(df)\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi=yellow_taxi_dataset(linklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a50ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi=pd.read_csv(\"Yellow_Taxi_Sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b439d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_yellowtaxi(df_taxi):\n",
    "    \n",
    "    #location filter\n",
    "    pick_long_check=(df_taxi[\"pickup_longitude\"]>= -74.242330) & (df_taxi[\"pickup_longitude\"]<= -73.717047)\n",
    "    drop_long_check=(df_taxi[\"dropoff_longitude\"]>= -74.242330) & (df_taxi[\"dropoff_longitude\"]<= -73.717047)\n",
    "    pick_latt_check=(df_taxi[\"pickup_latitude\"]>= 40.560445) & (df_taxi[\"pickup_latitude\"]<= 40.908524)\n",
    "    drop_latt_check=(df_taxi[\"dropoff_latitude\"]>= 40.560445) & (df_taxi[\"dropoff_latitude\"]<= 40.908524)\n",
    "\n",
    "    df_taxi=df_taxi[pick_long_check & drop_long_check & pick_latt_check & drop_latt_check]\n",
    "    \n",
    "    #drop columns with too many NAs\n",
    "    na_bar = len(df_taxi) * .8\n",
    "    df_taxi = df_taxi.dropna(thresh=na_bar, axis=1)\n",
    "    \n",
    "    #add distance column\n",
    "    df_taxi['distance'] = df_taxi.apply(distance, axis=1)\n",
    "    \n",
    "    #drop trip_distance col\n",
    "    df_taxi = df_taxi.drop(['trip_distance'], axis = 1)\n",
    "\n",
    "    \n",
    "    return df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a1f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_taxi=pd.read_csv(\"Yellow_Taxi_Sample.csv\")\n",
    "df_taxi=clean_yellowtaxi(df_taxi)\n",
    "df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaefe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Case for Distance Function\n",
    "def distance_test():\n",
    "    \n",
    "    distance_test=round(distance(df_taxi.iloc[[0]]),2)   \n",
    "    assert distance_test== 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cab860",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e27cc0",
   "metadata": {},
   "source": [
    "## Weather Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concact_weather_data():\n",
    "    # setting the path for joining multiple files\n",
    "    files = os.path.join(\"/Users/nat/Desktop/tfa/proj\", \"*weather.csv\") #directory change needed\n",
    "\n",
    "    # list of merged files returned\n",
    "    files = glob.glob(files)\n",
    "\n",
    "    # joining files with concat and store csv\n",
    "    df_weather = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "    #df_weather.to_csv('weather_all.csv',index=False)  \n",
    "    \n",
    "    return df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather=concact_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6403a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisakuai/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7,8,9,10,13,17,18,19,40,41,42,61,65,78,88,89,90,91,92,93,94,95,96,97,98,99) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_weather=pd.read_csv(\"weather_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86594950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df_weather):\n",
    "    #choose only useful cols\n",
    "    df_weather_cleaned = df_weather[df_weather.filter(regex='DATE|speed|Speed|Precipitation|precipitation').columns[:8]]\n",
    "    \n",
    "    df_weather_hourly = df_weather_cleaned[df_weather_cleaned.filter(regex='DATE|hourly|Hourly').columns[:]]\n",
    "    df_weather_daily = df_weather_cleaned[df_weather_cleaned.filter(regex='DATE|daily|Daily').columns[:]]\n",
    "    \n",
    "    return df_weather_hourly,df_weather_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05c092dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weather_hourly,df_weather_daily=clean_weather(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965e22c",
   "metadata": {},
   "source": [
    "# Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d60429",
   "metadata": {},
   "source": [
    "#Use SQLAlchemy to create a SQLite\n",
    "#explanation needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2adc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:\n",
    "# 1. Is it correct to store 4 tables into final_proj.db?\n",
    "# 2. daily weather data; too many missing values\n",
    "# 3. how to save as schema.sqlp file? we only have .db file now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ff0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy.orm import validates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dff99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def database():\n",
    "    \n",
    "    engine = create_engine(f\"sqlite:///final_project.db\")\n",
    "    Base = declarative_base()\n",
    "    \n",
    "    # Convert csv file into sql & insert into data.db\n",
    "    df_uber.to_sql('Uber_trips', con=engine, index=True, index_label='id', if_exists='replace')\n",
    "    df_taxi.to_sql('Yellow_Taxi_trips', con=engine, index=True, index_label='id', if_exists='replace')\n",
    "    df_weather_daily.to_sql('Daily_Weather_Information', con=engine, index=True, index_label='id', if_exists='replace')\n",
    "    df_weather_hourly.to_sql('Hourly_Weather_Information', con=engine, index=True, index_label='id', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bb391f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'database' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d9cda473472b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'database' is not defined"
     ]
    }
   ],
   "source": [
    "database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b48318f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01T00:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01T01:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01T02:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01T03:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01T04:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77967</th>\n",
       "      <td>2010-12-31T19:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77968</th>\n",
       "      <td>2010-12-31T20:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77969</th>\n",
       "      <td>2010-12-31T21:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77970</th>\n",
       "      <td>2010-12-31T22:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77971</th>\n",
       "      <td>2010-12-31T23:51:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77972 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE HourlyPrecipitation  HourlyWindGustSpeed  \\\n",
       "0      2012-01-01T00:51:00                 NaN                  NaN   \n",
       "1      2012-01-01T01:51:00                 NaN                  NaN   \n",
       "2      2012-01-01T02:51:00                 NaN                  NaN   \n",
       "3      2012-01-01T03:51:00                 NaN                  NaN   \n",
       "4      2012-01-01T04:51:00                 NaN                  NaN   \n",
       "...                    ...                 ...                  ...   \n",
       "77967  2010-12-31T19:51:00                 NaN                  NaN   \n",
       "77968  2010-12-31T20:51:00                 NaN                  NaN   \n",
       "77969  2010-12-31T21:51:00                 NaN                  NaN   \n",
       "77970  2010-12-31T22:51:00                 NaN                  NaN   \n",
       "77971  2010-12-31T23:51:00                 NaN                  NaN   \n",
       "\n",
       "       HourlyWindSpeed  \n",
       "0                  6.0  \n",
       "1                  7.0  \n",
       "2                  6.0  \n",
       "3                  5.0  \n",
       "4                  0.0  \n",
       "...                ...  \n",
       "77967              5.0  \n",
       "77968              7.0  \n",
       "77969              7.0  \n",
       "77970              6.0  \n",
       "77971              7.0  \n",
       "\n",
       "[77972 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_daily['DailyAverageWindSpeed'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608c670",
   "metadata": {},
   "source": [
    "# Part 3: Understanding Sata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68eb395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Connection at 0x7f97394f9030>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(\"final_project.db\")\n",
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476e41d",
   "metadata": {},
   "source": [
    "1.\tFor 01-2009 through 06-2015, what hour of the day was the most popular to take a Yellow Taxi? The result should have 24 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae748396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q1 = connection.execute(\n",
    "        \"\"\"SELECT strftime('%H', y.pickup_datetime) as Hour, count(*) as Counts\n",
    "                                From Yellow_Taxi_trips y\n",
    "                                where date(y.pickup_datetime)>=\"2009-01-01\" and date(y.pickup_datetime)<=\"2015-06-30\"\n",
    "                                group by Hour\n",
    "                                order by Counts desc\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1258207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in Q1:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5159be",
   "metadata": {},
   "source": [
    "2.\tFor the same time frame, what day of the week was the most popular to take an Uber? The result should have 7 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q2 = connection.execute(\n",
    "        \"\"\"SELECT strftime('%w', u.pickup_datetime) as weekofday, count(*) as Counts\n",
    "                                From Uber_trips u\n",
    "                                where date(u.pickup_datetime)>=\"2009-01-01\" and date(u.pickup_datetime)<=\"2015-06-30\"\n",
    "                                group by weekofday\n",
    "                                order by Counts desc\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in Q2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccd674",
   "metadata": {},
   "source": [
    "3.\tWhat is the 95% percentile of distance traveled for all hired trips during July 2013?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q3 = connection.execute(\n",
    "        \"\"\" with newtable as \n",
    "                (SELECT distance from Uber_trips\n",
    "                 Where date(pickup_datetime)<=\"2013-07-31\" and date(pickup_datetime)>=\"2013-07-1\"\n",
    "            \n",
    "                 Union all\n",
    "            \n",
    "                SELECT distance from Yellow_Taxi_trips\n",
    "                Where date(pickup_datetime)<=\"2013-07-31\" and date(pickup_datetime)>=\"2013-07-1\")\n",
    "            \n",
    "            Select distance as \"95% distance\"\n",
    "            FROM newtable\n",
    "            ORDER BY distance ASC\n",
    "            LIMIT 1\n",
    "            OFFSET (SELECT\n",
    "             COUNT(*)\n",
    "            FROM newtable\n",
    "            ) * 95 / 100 - 1\n",
    "            \n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in Q3:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b58c62",
   "metadata": {},
   "source": [
    "4.\tWhat were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q4 = connection.execute(\n",
    "        \"\"\" with newtable as \n",
    "                (SELECT distance, date(pickup_datetime) as date from Uber_trips\n",
    "                 Where strftime('%Y', pickup_datetime)=\"2009\"\n",
    "            \n",
    "                 Union all\n",
    "            \n",
    "                SELECT distance, date(pickup_datetime) as date from Yellow_Taxi_trips\n",
    "                Where strftime('%Y', pickup_datetime)=\"2009\")\n",
    "            \n",
    "            Select date, Avg(distance) as Avg_dist \n",
    "            FROM newtable\n",
    "            Group by date\n",
    "            Order by Count(*) desc\n",
    "            LIMIT 10\n",
    "            \n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in Q4:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea8291",
   "metadata": {},
   "source": [
    "5.\tWhich 10 days in 2014 were the windiest on average, and how many hired trips were made on those days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q5 = connection.execute(\n",
    "        \"\"\" with newtable as \n",
    "            (Select date, sum(num_trip) as num_trips\n",
    "                from (SELECT date(pickup_datetime) as date, count(*) as num_trip from Uber_trips\n",
    "                     Where strftime('%Y', pickup_datetime)=\"2014\"\n",
    "                     Group by date\n",
    "\n",
    "                     Union all\n",
    "\n",
    "                    SELECT date(pickup_datetime) as date, count(*) as num_trip from Yellow_Taxi_trips\n",
    "                    Where strftime('%Y', pickup_datetime)=\"2014\"\n",
    "                    Group by date)\n",
    "                group by date)\n",
    "                    \n",
    "               \n",
    "               \n",
    "              Select n.date, n.num_trips\n",
    "              from newtable n\n",
    "              Join\n",
    "                (Select date(DATE) as date, DailyAverageWindSpeed\n",
    "                From Daily_Weather_Information\n",
    "                Where strftime('%Y', DATE)=\"2014\"\n",
    "                Order by DailyAverageWindSpeed Desc\n",
    "                Limit 10) w\n",
    "            on n.date=w.date\n",
    "                \n",
    "            \n",
    "          \n",
    "\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47eadb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in Q5:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce356a21",
   "metadata": {},
   "source": [
    "6.\tDuring Hurricane Sandy in NYC (Oct 29-30, 2012), plus the week leading up and the week after, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed? There should be an entry for every single hour, even if no rides were taken, no precipitation was measured, or there was no wind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10657103",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q6 = connection.execute(\n",
    "        \"\"\" WITH RECURSIVE dates(x) AS( \n",
    "                SELECT '2012-10-22'\n",
    "                UNION ALL \n",
    "                SELECT DATE(x, '+1 DAYS')FROM dates WHERE x<'2012-11-1' \n",
    "                Limit 16),\n",
    "                \n",
    "            trips as (SELECT strftime('%H', u.pickup_datetime) as hour, count(*) as num_trip\n",
    "                     from Uber_trips u\n",
    "                     Join dates d on date(u.pickup_datetime)=d.x\n",
    "                     Group by hour\n",
    "                     \n",
    "                 Union all\n",
    "\n",
    "                SELECT strftime('%H', y.pickup_datetime) as hour, count(*) as num_trip\n",
    "                    from Yellow_Taxi_trips y\n",
    "                    Join dates d on date(y.pickup_datetime)=d.x\n",
    "                    Group by hour),\n",
    "                    \n",
    "            weather as (Select strftime('%H', w.DATE) as hour, \n",
    "                            sum(w.HourlyPrecipitation)as percipitation, \n",
    "                            sum(w.HourlyWindSpeed) as windspeed \n",
    "                    From Hourly_Weather_Information  w\n",
    "                    Left Join dates d\n",
    "                    on w.date=d.x\n",
    "                    group by hour\n",
    "            )\n",
    "                \n",
    "            Select t.hour, t.trips, h.percipitation, h.windspeed  \n",
    "            From weather h\n",
    "            Join (Select hour, sum(num_trip) as trips\n",
    "                     from trips\n",
    "                     group by hour) t\n",
    "            on t.hour=h.hour\n",
    "            \n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1deccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00', 96, 33.52000000000008, 15715.0)\n",
      "('01', 77, 32.300000000000054, 15289.0)\n",
      "('02', 68, 28.160000000000057, 15568.0)\n",
      "('03', 31, 33.840000000000074, 15924.0)\n",
      "('04', 28, 29.600000000000072, 15596.0)\n",
      "('05', 25, 25.060000000000024, 15672.0)\n",
      "('06', 52, 24.150000000000016, 16928.0)\n",
      "('07', 79, 29.900000000000066, 18022.0)\n",
      "('08', 89, 29.060000000000052, 19060.0)\n",
      "('09', 102, 30.220000000000045, 19772.0)\n",
      "('10', 123, 26.58000000000005, 19049.0)\n",
      "('11', 129, 28.38000000000004, 19248.0)\n",
      "('12', 126, 29.330000000000027, 19288.0)\n",
      "('13', 129, 28.590000000000064, 19070.0)\n",
      "('14', 114, 35.93000000000006, 19843.0)\n",
      "('15', 117, 38.45000000000002, 19266.0)\n",
      "('16', 94, 44.25000000000004, 18647.0)\n",
      "('17', 139, 35.90000000000006, 18300.0)\n",
      "('18', 160, 34.520000000000095, 17084.0)\n",
      "('19', 128, 41.3300000000001, 16654.0)\n",
      "('20', 162, 35.30000000000009, 16439.0)\n",
      "('21', 145, 38.680000000000064, 16474.0)\n",
      "('22', 132, 33.00000000000004, 15915.0)\n",
      "('23', 100, 32.71000000000007, 15635.0)\n"
     ]
    }
   ],
   "source": [
    "for item in Q6:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
