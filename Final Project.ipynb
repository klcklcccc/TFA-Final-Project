{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c21a832",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2292395b",
   "metadata": {},
   "source": [
    "use Markdown cells to describe what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3da867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import bs4\n",
    "import pandas as pd\n",
    "import re\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237859c",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d333efa",
   "metadata": {},
   "source": [
    "## Uber Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5498c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uber=pd.read_csv(\"uber_rides_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835d574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(row):\n",
    "    R = 6373.0\n",
    "    \n",
    "    lon1 = radians(row[\"pickup_longitude\"])\n",
    "    lat1 = radians(row[\"pickup_latitude\"])\n",
    "    \n",
    "    lon2 = radians(row[\"dropoff_longitude\"])\n",
    "    lat2 = radians(row[\"dropoff_latitude\"])\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67515cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uber_data_cleaning(df_uber):\n",
    "    df_uber.dropna()\n",
    "    df_uber.drop(\"Unnamed: 0\" , axis=1, inplace=True)\n",
    "    \n",
    "    pick_long_check=(df_uber[\"pickup_longitude\"]>= -74.242330) & (df_uber[\"pickup_longitude\"]<= -73.717047)\n",
    "    drop_long_check=(df_uber[\"dropoff_longitude\"]>= -74.242330) & (df_uber[\"dropoff_longitude\"]<= -73.717047)\n",
    "    pick_latt_check=(df_uber[\"pickup_latitude\"]>= 40.560445) & (df_uber[\"pickup_latitude\"]<= 40.908524)\n",
    "    drop_latt_check=(df_uber[\"dropoff_latitude\"]>= 40.560445) & (df_uber[\"dropoff_latitude\"]<= 40.908524)\n",
    "\n",
    "    df_uber=df_uber[pick_long_check & drop_long_check & pick_latt_check & drop_latt_check]\n",
    "    \n",
    "    df_uber['pickup_datetime'] = pd.to_datetime(df_uber['pickup_datetime'])\n",
    "    df_uber['pickup_datetime']=df_uber['pickup_datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df_uber['distance'] = df_uber.apply(distance, axis=1)\n",
    "    \n",
    "    return df_uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c4806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-de374cc63ef3>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_uber['pickup_datetime'] = pd.to_datetime(df_uber['pickup_datetime'])\n",
      "<ipython-input-6-de374cc63ef3>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_uber['pickup_datetime']=df_uber['pickup_datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
      "<ipython-input-6-de374cc63ef3>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_uber['distance'] = df_uber.apply(distance, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_uber=uber_data_cleaning(df_uber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799d0e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>1.683851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>5.037958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>1.662205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>4.476855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00.00000053</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00.0000008</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>1.875639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00.00000078</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>12.854353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25.0000004</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>3.540827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00.00000076</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>5.419484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  key  fare_amount      pickup_datetime  \\\n",
       "0         2015-05-07 19:52:06.0000003          7.5  2015-05-07 19:52:06   \n",
       "1         2009-07-17 20:04:56.0000002          7.7  2009-07-17 20:04:56   \n",
       "2        2009-08-24 21:45:00.00000061         12.9  2009-08-24 21:45:00   \n",
       "3         2009-06-26 08:22:21.0000001          5.3  2009-06-26 08:22:21   \n",
       "4       2014-08-28 17:47:00.000000188         16.0  2014-08-28 17:47:00   \n",
       "...                               ...          ...                  ...   \n",
       "199995   2012-10-28 10:49:00.00000053          3.0  2012-10-28 10:49:00   \n",
       "199996    2014-03-14 01:09:00.0000008          7.5  2014-03-14 01:09:00   \n",
       "199997   2009-06-29 00:42:00.00000078         30.9  2009-06-29 00:42:00   \n",
       "199998    2015-05-20 14:56:25.0000004         14.5  2015-05-20 14:56:25   \n",
       "199999   2010-05-15 04:08:00.00000076         14.1  2010-05-15 04:08:00   \n",
       "\n",
       "        pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0             -73.999817        40.738354         -73.999512   \n",
       "1             -73.994355        40.728225         -73.994710   \n",
       "2             -74.005043        40.740770         -73.962565   \n",
       "3             -73.976124        40.790844         -73.965316   \n",
       "4             -73.925023        40.744085         -73.973082   \n",
       "...                  ...              ...                ...   \n",
       "199995        -73.987042        40.739367         -73.986525   \n",
       "199996        -73.984722        40.736837         -74.006672   \n",
       "199997        -73.986017        40.756487         -73.858957   \n",
       "199998        -73.997124        40.725452         -73.983215   \n",
       "199999        -73.984395        40.720077         -73.985508   \n",
       "\n",
       "        dropoff_latitude  passenger_count   distance  \n",
       "0              40.723217                1   1.683851  \n",
       "1              40.750325                1   2.458361  \n",
       "2              40.772647                1   5.037958  \n",
       "3              40.803349                3   1.662205  \n",
       "4              40.761247                5   4.476855  \n",
       "...                  ...              ...        ...  \n",
       "199995         40.740297                1   0.112245  \n",
       "199996         40.739620                1   1.875639  \n",
       "199997         40.692588                2  12.854353  \n",
       "199998         40.695415                1   3.540827  \n",
       "199999         40.768793                1   5.419484  \n",
       "\n",
       "[195472 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9028708e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d5cb124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ca56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_uber.to_csv('uber_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf074d9",
   "metadata": {},
   "source": [
    "## Yellow Taxi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_parser(): \n",
    "    # Scrapping out link for each of yellow trip data\n",
    "    \n",
    "    response = requests.get('https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page')\n",
    "    soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "    parse = str(soup.find_all(\"li\")).split()\n",
    "    pattern = re.compile(r\"href=\\\"https:\\/\\/s3\\.amazonaws\\.com\\/nyc\\-tlc\\/trip\\+data\\/yellow\\_tripdata\\_20[0-1]\\d\")\n",
    "    newlist = list(filter(pattern.match, parse))\n",
    "    newlist = newlist[42:]\n",
    "    linklist=[]\n",
    "    for item in newlist:\n",
    "        linklist.append(item.split('href=\"')[1][:-1])\n",
    "    return linklist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linklist=link_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ead01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_taxi_dataset(linklist):\n",
    "    result=pd.DataFrame()\n",
    "    #Data collection of 2015's yellow taxi data\n",
    "    for link in linklist[:12]:\n",
    "        req = requests.get(link)\n",
    "        url_content = req.content\n",
    "    \n",
    "        s=str(url_content,'utf-8')\n",
    "        data = StringIO(s) \n",
    "        df=pd.read_csv(data, error_bad_lines=False)\n",
    "        df.drop(\"improvement_surcharge\" , axis=1, inplace=True)\n",
    "        df = df.iloc[: , :-1]\n",
    "        df.columns=['vendor_id','pickup_datetime','dropoff_datetime','passenger_count','trip_distance','pickup_longitude',\n",
    "                'pickup_latitude','rate_code','store_and_fwd_flag','dropoff_longitude','dropoff_latitude','payment_type',\n",
    "                'fare_amount','surcharge','mta_tax','tip_amount','tolls_amount','total_amount']\n",
    "        df = df.sample(n=3000)\n",
    "    \n",
    "        result=result.append(df)\n",
    "    #Data collection of years from 2009 to 2014    \n",
    "    for link in linklist[12:]:\n",
    "        req = requests.get(link)\n",
    "        url_content = req.content\n",
    "    \n",
    "        s=str(url_content,'utf-8')\n",
    "        data = StringIO(s) \n",
    "        df=pd.read_csv(data, error_bad_lines=False)\n",
    "        df.columns=['vendor_id','pickup_datetime','dropoff_datetime','passenger_count','trip_distance','pickup_longitude',\n",
    "                'pickup_latitude','rate_code','store_and_fwd_flag','dropoff_longitude','dropoff_latitude','payment_type',\n",
    "                'fare_amount','surcharge','mta_tax','tip_amount','tolls_amount','total_amount']\n",
    "        df = df.sample(n=3000)\n",
    "    \n",
    "        result=result.append(df)\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi=yellow_taxi_dataset(linklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a50ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisakuai/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0,8,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_taxi=pd.read_csv(\"Yellow_Taxi_Sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b439d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_yellowtaxi(df_taxi):\n",
    "    \n",
    "    #location filter\n",
    "    pick_long_check=(df_taxi[\"pickup_longitude\"]>= -74.242330) & (df_taxi[\"pickup_longitude\"]<= -73.717047)\n",
    "    drop_long_check=(df_taxi[\"dropoff_longitude\"]>= -74.242330) & (df_taxi[\"dropoff_longitude\"]<= -73.717047)\n",
    "    pick_latt_check=(df_taxi[\"pickup_latitude\"]>= 40.560445) & (df_taxi[\"pickup_latitude\"]<= 40.908524)\n",
    "    drop_latt_check=(df_taxi[\"dropoff_latitude\"]>= 40.560445) & (df_taxi[\"dropoff_latitude\"]<= 40.908524)\n",
    "\n",
    "    df_taxi=df_taxi[pick_long_check & drop_long_check & pick_latt_check & drop_latt_check]\n",
    "    \n",
    "    #drop columns with too many NAs\n",
    "    na_bar = len(df_taxi) * .8\n",
    "    df_taxi = df_taxi.dropna(thresh=na_bar, axis=1)\n",
    "    \n",
    "    #add distance column\n",
    "    df_taxi['distance'] = df_taxi.apply(distance, axis=1)\n",
    "    \n",
    "    #drop trip_distance col\n",
    "    df_taxi = df_taxi.drop(['trip_distance'], axis = 1)\n",
    "\n",
    "    \n",
    "    return df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "921a1f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-24 14:58:38</td>\n",
       "      <td>2015-01-24 15:02:19</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.956810</td>\n",
       "      <td>40.781162</td>\n",
       "      <td>-73.955429</td>\n",
       "      <td>40.773361</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>0.875471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-08 15:39:52</td>\n",
       "      <td>2015-01-08 15:44:22</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.975601</td>\n",
       "      <td>40.752163</td>\n",
       "      <td>-73.981140</td>\n",
       "      <td>40.744507</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.971107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-07 15:21:40</td>\n",
       "      <td>2015-01-07 15:29:07</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.952255</td>\n",
       "      <td>40.777321</td>\n",
       "      <td>-73.959785</td>\n",
       "      <td>40.766941</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1.317316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-10 18:19:43</td>\n",
       "      <td>2015-01-10 18:26:58</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.995934</td>\n",
       "      <td>40.732300</td>\n",
       "      <td>-73.997925</td>\n",
       "      <td>40.736084</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.453140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-01-24 12:16:16</td>\n",
       "      <td>2015-01-24 12:30:55</td>\n",
       "      <td>5</td>\n",
       "      <td>-73.978249</td>\n",
       "      <td>40.752361</td>\n",
       "      <td>-74.005623</td>\n",
       "      <td>40.715229</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>4.730957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251995</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-12-13 09:12:35</td>\n",
       "      <td>2009-12-13 09:14:35</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990913</td>\n",
       "      <td>40.670626</td>\n",
       "      <td>-73.991142</td>\n",
       "      <td>40.669925</td>\n",
       "      <td>Cash</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.080330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251996</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-12-24 14:19:00</td>\n",
       "      <td>2009-12-24 14:37:00</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.975545</td>\n",
       "      <td>40.728643</td>\n",
       "      <td>-73.951623</td>\n",
       "      <td>40.783325</td>\n",
       "      <td>CASH</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.20</td>\n",
       "      <td>6.407539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251997</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-12-27 21:03:51</td>\n",
       "      <td>2009-12-27 21:22:37</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.999803</td>\n",
       "      <td>40.726753</td>\n",
       "      <td>-73.993088</td>\n",
       "      <td>40.665041</td>\n",
       "      <td>Cash</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.70</td>\n",
       "      <td>6.887535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251998</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-12-12 20:25:55</td>\n",
       "      <td>2009-12-12 20:41:44</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.997882</td>\n",
       "      <td>40.751496</td>\n",
       "      <td>-73.993273</td>\n",
       "      <td>40.722716</td>\n",
       "      <td>Cash</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.50</td>\n",
       "      <td>3.224676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251999</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-12-04 22:49:00</td>\n",
       "      <td>2009-12-04 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.981078</td>\n",
       "      <td>40.781872</td>\n",
       "      <td>-73.955767</td>\n",
       "      <td>40.779552</td>\n",
       "      <td>Credit</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.10</td>\n",
       "      <td>2.147378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246483 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vendor_id      pickup_datetime     dropoff_datetime  passenger_count  \\\n",
       "0              1  2015-01-24 14:58:38  2015-01-24 15:02:19                1   \n",
       "1              1  2015-01-08 15:39:52  2015-01-08 15:44:22                1   \n",
       "2              2  2015-01-07 15:21:40  2015-01-07 15:29:07                1   \n",
       "3              2  2015-01-10 18:19:43  2015-01-10 18:26:58                1   \n",
       "4              2  2015-01-24 12:16:16  2015-01-24 12:30:55                5   \n",
       "...          ...                  ...                  ...              ...   \n",
       "251995       CMT  2009-12-13 09:12:35  2009-12-13 09:14:35                1   \n",
       "251996       VTS  2009-12-24 14:19:00  2009-12-24 14:37:00                2   \n",
       "251997       CMT  2009-12-27 21:03:51  2009-12-27 21:22:37                1   \n",
       "251998       CMT  2009-12-12 20:25:55  2009-12-12 20:41:44                3   \n",
       "251999       VTS  2009-12-04 22:49:00  2009-12-04 23:00:00                1   \n",
       "\n",
       "        pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0             -73.956810        40.781162         -73.955429   \n",
       "1             -73.975601        40.752163         -73.981140   \n",
       "2             -73.952255        40.777321         -73.959785   \n",
       "3             -73.995934        40.732300         -73.997925   \n",
       "4             -73.978249        40.752361         -74.005623   \n",
       "...                  ...              ...                ...   \n",
       "251995        -73.990913        40.670626         -73.991142   \n",
       "251996        -73.975545        40.728643         -73.951623   \n",
       "251997        -73.999803        40.726753         -73.993088   \n",
       "251998        -73.997882        40.751496         -73.993273   \n",
       "251999        -73.981078        40.781872         -73.955767   \n",
       "\n",
       "        dropoff_latitude payment_type  fare_amount  surcharge  mta_tax  \\\n",
       "0              40.773361            1          5.0        0.0      0.5   \n",
       "1              40.744507            2          4.5        0.0      0.5   \n",
       "2              40.766941            2          6.5        0.0      0.5   \n",
       "3              40.736084            2          6.0        0.0      0.5   \n",
       "4              40.715229            2         13.5        0.0      0.5   \n",
       "...                  ...          ...          ...        ...      ...   \n",
       "251995         40.669925         Cash          3.7        0.0      0.5   \n",
       "251996         40.783325         CASH         13.7        0.0      0.5   \n",
       "251997         40.665041         Cash         19.7        0.5      0.5   \n",
       "251998         40.722716         Cash         10.5        0.5      0.5   \n",
       "251999         40.779552       Credit          8.1        0.5      0.5   \n",
       "\n",
       "        tip_amount  tolls_amount  total_amount  distance  \n",
       "0             1.15           0.0          6.95  0.875471  \n",
       "1             0.00           0.0          5.30  0.971107  \n",
       "2             0.00           0.0          7.30  1.317316  \n",
       "3             0.00           0.0          6.80  0.453140  \n",
       "4             0.00           0.0         14.30  4.730957  \n",
       "...            ...           ...           ...       ...  \n",
       "251995        0.00           0.0          4.20  0.080330  \n",
       "251996        0.00           0.0         14.20  6.407539  \n",
       "251997        0.00           0.0         20.70  6.887535  \n",
       "251998        0.00           0.0         11.50  3.224676  \n",
       "251999        1.00           0.0         10.10  2.147378  \n",
       "\n",
       "[246483 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_taxi=pd.read_csv(\"Yellow_Taxi_Sample.csv\")\n",
    "df_taxi=clean_yellowtaxi(df_taxi)\n",
    "df_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcaefe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Case for Distance Function\n",
    "def distance_test():\n",
    "    \n",
    "    distance_test=round(distance(df_taxi.iloc[[0]]),2)   \n",
    "    assert distance_test== 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5cab860",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e27cc0",
   "metadata": {},
   "source": [
    "## Weather Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b8752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concact_weather_data():\n",
    "    # setting the path for joining multiple files\n",
    "    files = os.path.join(\"/Users/nat/Desktop/tfa/proj\", \"*weather.csv\") #directory change needed\n",
    "\n",
    "    # list of merged files returned\n",
    "    files = glob.glob(files)\n",
    "\n",
    "    # joining files with concat and store csv\n",
    "    df_weather = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "    #df_weather.to_csv('weather_all.csv',index=False)  \n",
    "    \n",
    "    return df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dfc2a25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7a802ded77f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_weather\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconcact_weather_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-c96f4a997f34>\u001b[0m in \u001b[0;36mconcact_weather_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# joining files with concat and store csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdf_weather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#df_weather.to_csv('weather_all.csv',index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "df_weather=concact_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf6403a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisakuai/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7,8,9,10,13,17,18,19,40,41,42,61,65,78,88,89,90,91,92,93,94,95,96,97,98,99) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_weather=pd.read_csv(\"weather_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86594950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather(df_weather):\n",
    "    #choose only useful cols\n",
    "    df_weather_cleaned = df_weather[df_weather.filter(regex='DATE|speed|Speed|Precipitation|precipitation').columns[:8]]\n",
    "    \n",
    "    df_weather_hourly = df_weather_cleaned[df_weather_cleaned.filter(regex='DATE|hourly|Hourly').columns[:]]\n",
    "    df_weather_daily = df_weather_cleaned[df_weather_cleaned.filter(regex='DATE|daily|Daily').columns[:]]\n",
    "    \n",
    "    return df_weather_hourly,df_weather_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05c092dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_weather_hourly,df_weather_daily=clean_weather(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965e22c",
   "metadata": {},
   "source": [
    "# Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d60429",
   "metadata": {},
   "source": [
    "#Use SQLAlchemy to create a SQLite\n",
    "#explanation needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2adc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:\n",
    "# 1. Is it correct to store 4 tables into final_proj.db?\n",
    "# 2. daily weather data; too many missing values\n",
    "# 3. how to save as schema.sqlp file? we only have .db file now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ff0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy.orm import validates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7dff99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def database():\n",
    "    \n",
    "    engine = create_engine(f\"sqlite:///final_project.db\", echo=True)\n",
    "    Base = declarative_base()\n",
    "    \n",
    "    # Convert csv file into sql & insert into data.db\n",
    "    df_uber.to_sql('Uber_trips', con=engine, index=True, index_label='id', if_exists='replace')\n",
    "    df_taxi.to_sql('Yellow_Taxi_trips', con=engine, index=True, index_label='id', if_exists='replace')\n",
    "    df_weather_daily.to_sql('Daily_Weather_Information', con=engine, index=True, index_label='id', if_exists='replace')\n",
    "    df_weather_hourly.to_sql('Hourly_Weather_Information', con=engine, index=True, index_label='id', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bb391f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-22 01:20:13,053 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"Uber_trips\")\n",
      "2022-04-22 01:20:13,055 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:13,056 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"Uber_trips\")\n",
      "2022-04-22 01:20:13,056 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:13,058 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:13,058 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"Uber_trips\" (\n",
      "\tid BIGINT, \n",
      "\t\"key\" TEXT, \n",
      "\tfare_amount FLOAT, \n",
      "\tpickup_datetime TEXT, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\tpassenger_count BIGINT, \n",
      "\tdistance FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-04-22 01:20:13,059 INFO sqlalchemy.engine.Engine [no key 0.00029s] ()\n",
      "2022-04-22 01:20:13,060 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_Uber_trips_id\" ON \"Uber_trips\" (id)\n",
      "2022-04-22 01:20:13,061 INFO sqlalchemy.engine.Engine [no key 0.00039s] ()\n",
      "2022-04-22 01:20:13,062 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:13,252 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:14,530 INFO sqlalchemy.engine.Engine INSERT INTO \"Uber_trips\" (id, \"key\", fare_amount, pickup_datetime, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count, distance) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2022-04-22 01:20:14,531 INFO sqlalchemy.engine.Engine [generated in 1.08809s] ((0, '2015-05-07 19:52:06.0000003', 7.5, '2015-05-07 19:52:06', -73.99981689453125, 40.73835372924805, -73.99951171875, 40.72321701049805, 1, 1.6838511852242786), (1, '2009-07-17 20:04:56.0000002', 7.7, '2009-07-17 20:04:56', -73.994355, 40.728225, -73.99471, 40.750325, 1, 2.458361376443877), (2, '2009-08-24 21:45:00.00000061', 12.9, '2009-08-24 21:45:00', -74.005043, 40.74077, -73.962565, 40.772647, 1, 5.0379582221658445), (3, '2009-06-26 08:22:21.0000001', 5.3, '2009-06-26 08:22:21', -73.976124, 40.790844, -73.965316, 40.803349, 3, 1.6622050981962737), (4, '2014-08-28 17:47:00.000000188', 16.0, '2014-08-28 17:47:00', -73.925023, 40.744085, -73.97308199999999, 40.761247, 5, 4.4768549072953325), (5, '2011-02-12 02:27:09.0000006', 4.9, '2011-02-12 02:27:09', -73.96901899999999, 40.75591, -73.96901899999999, 40.75591, 1, 0.0), (6, '2014-10-12 07:04:00.0000002', 24.5, '2014-10-12 07:04:00', -73.96144699999999, 40.693965000000006, -73.871195, 40.774297, 5, 11.734697512602486), (8, '2012-02-17 09:32:00.00000043', 9.7, '2012-02-17 09:32:00', -73.975187, 40.745767, -74.00272, 40.743537, 1, 2.3334432997212855)  ... displaying 10 of 195472 total bound parameter sets ...  (199998, '2015-05-20 14:56:25.0000004', 14.5, '2015-05-20 14:56:25', -73.99712371826173, 40.7254524230957, -73.98321533203125, 40.69541549682617, 1, 3.5408266479309387), (199999, '2010-05-15 04:08:00.00000076', 14.1, '2010-05-15 04:08:00', -73.98439499999999, 40.720077, -73.985508, 40.768793, 1, 5.419484244981255))\n",
      "2022-04-22 01:20:14,942 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:14,966 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2022-04-22 01:20:14,966 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:15,056 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"Yellow_Taxi_trips\")\n",
      "2022-04-22 01:20:15,057 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:15,057 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"Yellow_Taxi_trips\")\n",
      "2022-04-22 01:20:15,057 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:15,059 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:15,059 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"Yellow_Taxi_trips\" (\n",
      "\tid BIGINT, \n",
      "\tvendor_id TEXT, \n",
      "\tpickup_datetime TEXT, \n",
      "\tdropoff_datetime TEXT, \n",
      "\tpassenger_count BIGINT, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\tpayment_type TEXT, \n",
      "\tfare_amount FLOAT, \n",
      "\tsurcharge FLOAT, \n",
      "\tmta_tax FLOAT, \n",
      "\ttip_amount FLOAT, \n",
      "\ttolls_amount FLOAT, \n",
      "\ttotal_amount FLOAT, \n",
      "\tdistance FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-04-22 01:20:15,059 INFO sqlalchemy.engine.Engine [no key 0.00026s] ()\n",
      "2022-04-22 01:20:15,061 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_Yellow_Taxi_trips_id\" ON \"Yellow_Taxi_trips\" (id)\n",
      "2022-04-22 01:20:15,061 INFO sqlalchemy.engine.Engine [no key 0.00026s] ()\n",
      "2022-04-22 01:20:15,062 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:15,262 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:17,450 INFO sqlalchemy.engine.Engine INSERT INTO \"Yellow_Taxi_trips\" (id, vendor_id, pickup_datetime, dropoff_datetime, passenger_count, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount, distance) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2022-04-22 01:20:17,451 INFO sqlalchemy.engine.Engine [generated in 1.85192s] ((0, 1, '2015-01-24 14:58:38', '2015-01-24 15:02:19', 1, -73.9568099975586, 40.78116226196289, -73.95542907714845, 40.77336120605469, 1, 5.0, 0.0, 0.5, 1.15, 0.0, 6.95, 0.875471203464845), (1, 1, '2015-01-08 15:39:52', '2015-01-08 15:44:22', 1, -73.97560119628906, 40.75216293334961, -73.98114013671875, 40.7445068359375, 2, 4.5, 0.0, 0.5, 0.0, 0.0, 5.3, 0.9711073199364172), (2, 2, '2015-01-07 15:21:40', '2015-01-07 15:29:07', 1, -73.95225524902342, 40.777320861816406, -73.95978546142578, 40.76694107055664, 2, 6.5, 0.0, 0.5, 0.0, 0.0, 7.3, 1.3173160625034415), (3, 2, '2015-01-10 18:19:43', '2015-01-10 18:26:58', 1, -73.99593353271484, 40.7322998046875, -73.9979248046875, 40.736083984375, 2, 6.0, 0.0, 0.5, 0.0, 0.0, 6.8, 0.4531400770018299), (4, 2, '2015-01-24 12:16:16', '2015-01-24 12:30:55', 5, -73.97824859619139, 40.75236129760742, -74.00562286376953, 40.71522903442384, 2, 13.5, 0.0, 0.5, 0.0, 0.0, 14.3, 4.730957091719965), (5, 2, '2015-01-09 04:24:32', '2015-01-09 04:29:00', 1, -73.97156524658203, 40.75795364379882, -73.99102783203125, 40.750579833984375, 2, 7.0, 0.5, 0.5, 0.0, 0.0, 8.3, 1.8335583177258232), (6, 1, '2015-01-10 12:56:08', '2015-01-10 13:08:06', 1, -73.99713134765625, 40.76277923583984, -74.01494598388672, 40.71132278442384, 1, 13.5, 0.0, 0.5, 2.0, 0.0, 16.0, 5.917147383609713), (7, 2, '2015-01-13 22:50:19', '2015-01-13 23:02:49', 1, -73.96750640869139, 40.758750915527344, -73.95794677734375, 40.80073928833008, 1, 13.5, 0.5, 0.5, 4.2, 0.0, 19.0, 4.739257272089024)  ... displaying 10 of 246483 total bound parameter sets ...  (251998, 'CMT', '2009-12-12 20:25:55', '2009-12-12 20:41:44', 3, -73.997882, 40.751496, -73.993273, 40.722716, 'Cash', 10.5, 0.5, 0.5, 0.0, 0.0, 11.5, 3.22467644053612), (251999, 'VTS', '2009-12-04 22:49:00', '2009-12-04 23:00:00', 1, -73.98107799999998, 40.781872, -73.95576699999998, 40.779552, 'Credit', 8.099999999999998, 0.5, 0.5, 1.0, 0.0, 10.1, 2.147378014286465))\n",
      "2022-04-22 01:20:18,148 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:18,188 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2022-04-22 01:20:18,189 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:18,204 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"Daily_Weather_Information\")\n",
      "2022-04-22 01:20:18,204 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:18,205 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"Daily_Weather_Information\")\n",
      "2022-04-22 01:20:18,206 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:18,207 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:18,208 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"Daily_Weather_Information\" (\n",
      "\tid BIGINT, \n",
      "\t\"DATE\" TEXT, \n",
      "\t\"DailyAverageWindSpeed\" FLOAT, \n",
      "\t\"DailyPeakWindSpeed\" FLOAT, \n",
      "\t\"DailyPrecipitation\" TEXT, \n",
      "\t\"DailySustainedWindSpeed\" FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-04-22 01:20:18,208 INFO sqlalchemy.engine.Engine [no key 0.00035s] ()\n",
      "2022-04-22 01:20:18,210 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_Daily_Weather_Information_id\" ON \"Daily_Weather_Information\" (id)\n",
      "2022-04-22 01:20:18,210 INFO sqlalchemy.engine.Engine [no key 0.00028s] ()\n",
      "2022-04-22 01:20:18,211 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:18,233 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:18,526 INFO sqlalchemy.engine.Engine INSERT INTO \"Daily_Weather_Information\" (id, \"DATE\", \"DailyAverageWindSpeed\", \"DailyPeakWindSpeed\", \"DailyPrecipitation\", \"DailySustainedWindSpeed\") VALUES (?, ?, ?, ?, ?, ?)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-22 01:20:18,527 INFO sqlalchemy.engine.Engine [generated in 0.24651s] ((0, '2012-01-01T00:51:00', None, None, None, None), (1, '2012-01-01T01:51:00', None, None, None, None), (2, '2012-01-01T02:51:00', None, None, None, None), (3, '2012-01-01T03:51:00', None, None, None, None), (4, '2012-01-01T04:51:00', None, None, None, None), (5, '2012-01-01T05:15:00', None, None, None, None), (6, '2012-01-01T05:35:00', None, None, None, None), (7, '2012-01-01T05:51:00', None, None, None, None)  ... displaying 10 of 77972 total bound parameter sets ...  (77970, '2010-12-31T22:51:00', None, None, None, None), (77971, '2010-12-31T23:51:00', None, None, None, None))\n",
      "2022-04-22 01:20:18,754 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:18,759 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2022-04-22 01:20:18,759 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:18,772 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"Hourly_Weather_Information\")\n",
      "2022-04-22 01:20:18,772 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:18,773 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"Hourly_Weather_Information\")\n",
      "2022-04-22 01:20:18,774 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2022-04-22 01:20:18,776 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:18,777 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"Hourly_Weather_Information\" (\n",
      "\tid BIGINT, \n",
      "\t\"DATE\" TEXT, \n",
      "\t\"HourlyPrecipitation\" TEXT, \n",
      "\t\"HourlyWindGustSpeed\" FLOAT, \n",
      "\t\"HourlyWindSpeed\" FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2022-04-22 01:20:18,777 INFO sqlalchemy.engine.Engine [no key 0.00041s] ()\n",
      "2022-04-22 01:20:18,779 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_Hourly_Weather_Information_id\" ON \"Hourly_Weather_Information\" (id)\n",
      "2022-04-22 01:20:18,780 INFO sqlalchemy.engine.Engine [no key 0.00060s] ()\n",
      "2022-04-22 01:20:18,781 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:18,800 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2022-04-22 01:20:19,080 INFO sqlalchemy.engine.Engine INSERT INTO \"Hourly_Weather_Information\" (id, \"DATE\", \"HourlyPrecipitation\", \"HourlyWindGustSpeed\", \"HourlyWindSpeed\") VALUES (?, ?, ?, ?, ?)\n",
      "2022-04-22 01:20:19,080 INFO sqlalchemy.engine.Engine [generated in 0.24161s] ((0, '2012-01-01T00:51:00', None, None, 6.0), (1, '2012-01-01T01:51:00', None, None, 7.0), (2, '2012-01-01T02:51:00', None, None, 6.0), (3, '2012-01-01T03:51:00', None, None, 5.0), (4, '2012-01-01T04:51:00', None, None, 0.0), (5, '2012-01-01T05:15:00', None, None, 8.0), (6, '2012-01-01T05:35:00', None, None, 9.0), (7, '2012-01-01T05:51:00', None, None, 6.0)  ... displaying 10 of 77972 total bound parameter sets ...  (77970, '2010-12-31T22:51:00', None, None, 6.0), (77971, '2010-12-31T23:51:00', None, None, 7.0))\n",
      "2022-04-22 01:20:19,244 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2022-04-22 01:20:19,251 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\n",
      "2022-04-22 01:20:19,252 INFO sqlalchemy.engine.Engine [raw sql] ()\n"
     ]
    }
   ],
   "source": [
    "database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48318f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f608c670",
   "metadata": {},
   "source": [
    "# Part 3: Understanding Sata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f68eb395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Connection at 0x7fdf483d8d50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(\"final_project.db\")\n",
    "connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476e41d",
   "metadata": {},
   "source": [
    "1.\tFor 01-2009 through 06-2015, what hour of the day was the most popular to take a Yellow Taxi? The result should have 24 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae748396",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q1 = connection.execute(\n",
    "        \"\"\"SELECT strftime('%H', y.pickup_datetime) as Hour, count(*) as Counts\n",
    "                                From Yellow_Taxi_trips y\n",
    "                                where date(y.pickup_datetime)>=\"2009-01-01\" and date(y.pickup_datetime)<=\"2015-06-30\"\n",
    "                                group by Hour\n",
    "                                order by Counts desc\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1258207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19', 14246)\n",
      "('18', 13868)\n",
      "('20', 13576)\n",
      "('21', 13047)\n",
      "('22', 12742)\n",
      "('14', 11446)\n",
      "('17', 11335)\n",
      "('23', 11295)\n",
      "('12', 11085)\n",
      "('15', 11070)\n",
      "('13', 11057)\n",
      "('09', 10625)\n",
      "('08', 10471)\n",
      "('11', 10438)\n",
      "('10', 10356)\n",
      "('16', 9615)\n",
      "('00', 9141)\n",
      "('07', 8282)\n",
      "('01', 6766)\n",
      "('02', 5013)\n",
      "('06', 4703)\n",
      "('03', 3685)\n",
      "('04', 2713)\n",
      "('05', 2224)\n"
     ]
    }
   ],
   "source": [
    "for row in Q1:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5159be",
   "metadata": {},
   "source": [
    "2.\tFor the same time frame, what day of the week was the most popular to take an Uber? The result should have 7 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40de7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q2 = connection.execute(\n",
    "        \"\"\"SELECT strftime('%w', u.pickup_datetime) as weekofday, count(*) as Counts\n",
    "                                From Uber_trips u\n",
    "                                where date(u.pickup_datetime)>=\"2009-01-01\" and date(u.pickup_datetime)<=\"2015-06-30\"\n",
    "                                group by weekofday\n",
    "                                order by Counts desc\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "590d8307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('5', 30166)\n",
      "('6', 29599)\n",
      "('4', 29338)\n",
      "('3', 28328)\n",
      "('2', 27526)\n",
      "('0', 25834)\n",
      "('1', 24681)\n"
     ]
    }
   ],
   "source": [
    "for item in Q2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccd674",
   "metadata": {},
   "source": [
    "3.\tWhat is the 95% percentile of distance traveled for all hired trips during July 2013?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6728f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection:\n",
    "    Q3 = connection.execute(\n",
    "        \"\"\" with newtable as \n",
    "                (SELECT distance from Uber_trips\n",
    "                 Where date(pickup_datetime)<=\"2013-07-31\" and date(pickup_datetime)>=\"2013-07-1\"\n",
    "            \n",
    "                 Union all\n",
    "            \n",
    "                SELECT distance from Yellow_Taxi_trips\n",
    "                Where date(pickup_datetime)<=\"2013-07-31\" and date(pickup_datetime)>=\"2013-07-1\")\n",
    "            \n",
    "            Select distance as \"95% distance\"\n",
    "            FROM newtable\n",
    "            ORDER BY distance ASC\n",
    "            LIMIT 1\n",
    "            OFFSET (SELECT\n",
    "             COUNT(*)\n",
    "            FROM newtable\n",
    "            ) * 95 / 100 - 1\n",
    "            \n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "924c7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10.430214496267116,)\n"
     ]
    }
   ],
   "source": [
    "for item in Q3:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
